#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ³•è¦æ¢æ–‡è½‰æ›å·¥å…· - å°‡Markdownæ ¼å¼çš„æ³•è¦è½‰æ›ç‚ºCSV
æ ¹æ“šæä¾›çš„PostgreSQLè¡¨çµæ§‹ç”Ÿæˆå°æ‡‰çš„CSVæ•¸æ“š
"""

import re
import csv
import json
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class ColumnConfig:
    """æ¬„ä½é…ç½®"""
    name: str
    default_value: Any = None

class LawArticleConverter:
    """æ³•è¦æ¢æ–‡è½‰æ›å™¨ - ä¸­æ–‡æ¬„ä½ï¼Œè‡ªå‹•æ“´å±•"""
    
    def __init__(self, config_file: Optional[str] = "law_config.json"):
        """
        åˆå§‹åŒ–è½‰æ›å™¨
        
        Args:
            config_file: æ³•è¦é…ç½®æ–‡ä»¶è·¯å¾‘ï¼Œé è¨­ä½¿ç”¨ law_config.json
        """
        self.law_definitions = self._load_law_definitions(config_file)
        self.columns = self._get_column_configs()
        
    def _load_law_definitions(self, config_file: Optional[str]) -> Dict[str, Dict[str, str]]:
        """è¼‰å…¥æ³•è¦å®šç¾© - çµ±ä¸€å¾ law_config.json ç®¡ç†"""
        if config_file and Path(config_file).exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    law_defs = config.get('law_definitions', {})
                    logger.info(f"âœ… å¾é…ç½®æ–‡ä»¶è¼‰å…¥ {len(law_defs)} å€‹æ³•è¦å®šç¾©: {config_file}")
                    return law_defs
            except Exception as e:
                logger.error(f"âŒ ç„¡æ³•è¼‰å…¥é…ç½®æ–‡ä»¶ {config_file}: {e}")
        
        # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œçµ¦å‡ºæ˜ç¢ºéŒ¯èª¤æç¤º
        logger.error(f"âŒ å¿…é ˆæä¾›æœ‰æ•ˆçš„é…ç½®æ–‡ä»¶: {config_file}")
        logger.error("ğŸ’¡ è«‹ç¢ºä¿ law_config.json å­˜åœ¨ä¸¦åŒ…å« law_definitions é…ç½®")
        return {}
    
    def _get_column_configs(self) -> List[ColumnConfig]:
        """å–å¾—æ¬„ä½é…ç½®"""
        return [
            ColumnConfig('æ³•è¦ä»£ç¢¼'),
            ColumnConfig('æ³•è¦åç¨±'),
            ColumnConfig('ä¿®æ­£æ—¥æœŸï¼ˆæ°‘åœ‹ï¼‰'),
            ColumnConfig('æ³•è¦é¡åˆ¥'),
            ColumnConfig('ä¸»ç®¡æ©Ÿé—œ'),
            ColumnConfig('ç« ç¯€ç·¨è™Ÿ'),
            ColumnConfig('ç« ç¯€æ¨™é¡Œ'),
            ColumnConfig('æ¢æ–‡ä¸»è™Ÿ'),
            ColumnConfig('æ¢æ–‡æ¬¡è™Ÿ'),
            ColumnConfig('æ¢æ–‡å®Œæ•´å…§å®¹')
        ]
        
    def add_law_definition(self, filename: str, law_info: Dict[str, str]):
        """å‹•æ…‹æ·»åŠ æ³•è¦å®šç¾©"""
        self.law_definitions[filename] = law_info
        logger.info(f"å·²æ·»åŠ æ³•è¦å®šç¾©: {filename}")
    
    def auto_detect_law_info(self, file_path: Path, content: str) -> Dict[str, str]:
        """è‡ªå‹•æª¢æ¸¬æ³•è¦è³‡è¨Š"""
        filename = file_path.name
        
        # å¾å…§å®¹ä¸­æå–æ³•è¦åç¨±å’Œä¿®æ­£æ—¥æœŸ
        law_name_match = re.search(r'æ³•è¦åç¨±ï¼š(.+)', content)
        revision_date_match = re.search(r'ä¿®æ­£æ—¥æœŸï¼š(.+)', content)
        
        # è‡ªå‹•ç”Ÿæˆæ³•è¦ä»£ç¢¼
        law_code = self._generate_law_code(filename)
        
        return {
            'law_code': law_code,
            'law_name': law_name_match.group(1).strip() if law_name_match else filename.replace('.md', ''),
            'revision_date_roc': revision_date_match.group(1).strip() if revision_date_match else '',
            'category': 'è‡ªå‹•æª¢æ¸¬',
            'authority': 'å¾…ç¢ºèª'
        }
    
    def _generate_law_code(self, filename: str) -> str:
        """è‡ªå‹•ç”Ÿæˆæ³•è¦ä»£ç¢¼"""
        name = filename.replace('.md', '')
        
        # é—œéµå­—æ˜ å°„
        keyword_mapping = {
            'ä¸å‹•ç”¢ç¶“ç´€': 'REA',
            'å…¬å¯“å¤§å»ˆ': 'CMCA', 
            'å…¬å¹³äº¤æ˜“': 'FTA',
            'æ¶ˆè²»è€…ä¿è­·': 'CPA',
            'æ–½è¡Œç´°å‰‡': 'RULES',
            'ç®¡ç†æ¢ä¾‹': 'ACT',
            'ç®¡ç†è¾¦æ³•': 'REG'
        }
        
        code_parts = []
        for keyword, code in keyword_mapping.items():
            if keyword in name:
                code_parts.append(code)
        
        if code_parts:
            return '-'.join(code_parts)
        else:
            # å›é€€æ–¹æ¡ˆï¼šä½¿ç”¨æª”åçš„å‰å¹¾å€‹å­—
            return 'AUTO-' + ''.join([c for c in name if c.isalnum()])[:6].upper()
        
    def parse_law_file(self, file_path: Path) -> List[Dict[str, Any]]:
        """è§£æå–®å€‹æ³•è¦æ–‡ä»¶ - æ”¯æŒè‡ªå‹•æª¢æ¸¬"""
        filename = file_path.name
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # å„ªå…ˆä½¿ç”¨å·²å®šç¾©çš„æ³•è¦è³‡è¨Šï¼Œå¦å‰‡è‡ªå‹•æª¢æ¸¬
        if filename in self.law_definitions:
            law_info = self.law_definitions[filename]
            logger.info(f"ä½¿ç”¨é å®šç¾©æ³•è¦è³‡è¨Š: {filename}")
        else:
            law_info = self.auto_detect_law_info(file_path, content)
            logger.info(f"è‡ªå‹•æª¢æ¸¬æ³•è¦è³‡è¨Š: {filename} -> {law_info['law_code']}")
            # å°‡æª¢æ¸¬åˆ°çš„è³‡è¨ŠåŠ å…¥å®šç¾©ä¸­ï¼Œä¾›å¾ŒçºŒä½¿ç”¨
            self.law_definitions[filename] = law_info
        
        # ç§»é™¤æª”æ¡ˆæœ€å‰é¢çš„æ³•è¦åç¨±å’Œä¿®æ­£æ—¥æœŸè¡Œ
        lines = content.split('\n')
        content_lines = []
        skip_next = False
        
        for line in lines:
            if skip_next and line.strip() == '':
                skip_next = False
                continue
            if line.startswith('æ³•è¦åç¨±ï¼š'):
                skip_next = True
                continue
            if skip_next:
                continue
            content_lines.append(line)
        
        content = '\n'.join(content_lines)
        
        # è§£æçµæ§‹
        articles = []
        current_chapter = {'no': 1, 'title': 'ç¸½å‰‡'}  # é è¨­ç« ç¯€
        
        # å…ˆæ‰¾å‡ºæ‰€æœ‰ç« ç¯€
        chapters = self._extract_chapters(content)
        
        # å¦‚æœæ²’æœ‰ç« ç¯€ï¼Œä½¿ç”¨é è¨­ç« ç¯€
        if not chapters:
            chapters = [{'no': 1, 'title': 'ç¸½å‰‡'}]
        
        # è§£ææ¢æ–‡
        articles = self._extract_articles(content, law_info, chapters)
        
        logger.info(f"è§£æ {filename}: {len(articles)} æ¢æ¢æ–‡")
        return articles
    
    def _extract_chapters(self, content: str) -> List[Dict[str, Any]]:
        """æå–ç« ç¯€è³‡è¨Š"""
        chapters = []
        
        # åŒ¹é…ç« ç¯€æ¨™é¡Œï¼ˆæ”¯æŒä¸­æ–‡æ•¸å­—å’Œé˜¿æ‹‰ä¼¯æ•¸å­—ï¼‰
        patterns = [
            r'^# ç¬¬\s*(\d+)\s*ç« \s*(.+)$',  # é˜¿æ‹‰ä¼¯æ•¸å­—ï¼šç¬¬1ç« 
            r'^# ç¬¬\s*([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)\s*ç« \s*(.+)$'  # ä¸­æ–‡æ•¸å­—ï¼šç¬¬ä¸€ç« 
        ]
        
        lines = content.split('\n')
        for line in lines:
            line = line.strip()
            for i, pattern in enumerate(patterns):
                match = re.match(pattern, line)
                if match:
                    chapter_num_str = match.group(1).strip()
                    chapter_title = match.group(2).strip()
                    
                    # ç°¡åŒ–ï¼šç›´æ¥ä½¿ç”¨é †åºç·¨è™Ÿ
                    chapter_no = len(chapters) + 1
                    full_title = f'ç¬¬{chapter_num_str}ç«  {chapter_title}'
                    
                    chapters.append({
                        'no': chapter_no,
                        'title': full_title
                    })
                    break
        
        return chapters
    
    def _extract_articles(self, content: str, law_info: Dict[str, str], 
                         chapters: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æå–æ¢æ–‡è³‡è¨Š"""
        articles = []
        
        # åˆ†å‰²å…§å®¹ï¼Œæ‰¾å‡ºæ¯ä¸€æ¢
        lines = content.split('\n')
        current_chapter = chapters[0] if chapters else {'no': 1, 'title': 'ç¸½å‰‡'}
        current_article = None
        current_text_lines = []
        
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºç« ç¯€æ¨™é¡Œ
            chapter_match = re.match(r'^# ç¬¬\s*([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+)\s*ç« ', line)
            if chapter_match:
                # ä¿å­˜ç•¶å‰æ¢æ–‡
                if current_article:
                    current_article['text_full'] = self._clean_article_text('\n'.join(current_text_lines))
                    articles.append(current_article)
                    current_article = None
                    current_text_lines = []
                
                # ç°¡åŒ–ï¼šæ ¹æ“šç« ç¯€å‡ºç¾é †åºæ›´æ–°ç•¶å‰ç« ç¯€
                chapter_index = len([c for c in chapters if 'used' in c]) if chapters else 0
                if chapter_index < len(chapters):
                    current_chapter = chapters[chapter_index]
                    current_chapter['used'] = True
                
                i += 1
                continue
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºæ¢æ–‡æ¨™é¡Œ
            article_match = re.match(r'^# ç¬¬\s*(\d+(?:-\d+)?)\s*æ¢(?:\s*(.*))?$', line)
            if article_match:
                # ä¿å­˜å‰ä¸€æ¢
                if current_article:
                    current_article['text_full'] = self._clean_article_text('\n'.join(current_text_lines))
                    articles.append(current_article)
                
                # è§£ææ¢è™Ÿ
                article_no_str = article_match.group(1)
                article_title = article_match.group(2) if article_match.group(2) else None
                
                if '-' in article_no_str:
                    main_no, sub_no = map(int, article_no_str.split('-'))
                else:
                    main_no = int(article_no_str)
                    sub_no = 0
                
                # å‰µå»ºæ–°çš„æ¢æ–‡è¨˜éŒ„
                current_article = {
                    'law_code': law_info['law_code'],
                    'law_name': law_info['law_name'],
                    'revision_date_roc': law_info['revision_date_roc'],
                    'category': law_info.get('category', ''),
                    'authority': law_info.get('authority', ''),
                    'chapter_no': current_chapter['no'],
                    'chapter_title': current_chapter['title'],
                    'article_no_main': main_no,
                    'article_no_sub': sub_no,
                    'title': article_title.strip() if article_title and article_title.strip() else None
                }
                current_text_lines = []
                i += 1
                continue
            
            # å¦‚æœåœ¨æ¢æ–‡å…§å®¹ä¸­ï¼Œç´¯ç©æ–‡å­—
            if current_article and line:
                # è·³éç©ºè¡Œå’Œç´”ç¬¦è™Ÿè¡Œ
                if line and not re.match(r'^[=\-\*\#\s]*$', line):
                    current_text_lines.append(line)
            
            i += 1
        
        # è™•ç†æœ€å¾Œä¸€æ¢
        if current_article:
            current_article['text_full'] = self._clean_article_text('\n'.join(current_text_lines))
            articles.append(current_article)
        
        return articles
    
    def _clean_article_text(self, text: str) -> str:
        """æ¸…ç†æ¢æ–‡å…§å®¹"""
        lines = text.split('\n')
        cleaned_lines = []
        
        for line in lines:
            line = line.strip()
            if line and not re.match(r'^[=\-\*\#\s]*$', line):
                # ç§»é™¤è¡Œé¦–çš„æ•¸å­—ç·¨è™Ÿï¼ˆå¦‚ 1 ã€2 ç­‰ï¼‰
                line = re.sub(r'^\d+\s+', '', line)
                cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines).strip()
    

    
    def convert_to_csv(self, input_dir: str, output_file: str):
        """è½‰æ›æ‰€æœ‰æ³•è¦æ–‡ä»¶ç‚ºCSV - å‹•æ…‹å¾é…ç½®æ–‡ä»¶ç²å–æ–‡ä»¶åˆ—è¡¨"""
        input_path = Path(input_dir)
        all_articles = []
        
        # å¾é…ç½®æ–‡ä»¶å‹•æ…‹ç²å–è¦è™•ç†çš„æ–‡ä»¶åˆ—è¡¨
        target_files = list(self.law_definitions.keys())
        
        if not target_files:
            logger.error("âŒ æ²’æœ‰æ‰¾åˆ°è¦è™•ç†çš„æ³•è¦æ–‡ä»¶é…ç½®")
            return
        
        logger.info(f"ğŸ“‹ å°‡è™•ç† {len(target_files)} å€‹æ³•è¦æ–‡ä»¶")
        
        for filename in target_files:
            file_path = input_path / filename
            if file_path.exists():
                articles = self.parse_law_file(file_path)
                all_articles.extend(articles)
            else:
                logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        # å¯«å…¥CSV
        self._write_csv(all_articles, output_file)
        
        logger.info(f"âœ… è½‰æ›å®Œæˆï¼ç¸½å…± {len(all_articles)} æ¢æ¢æ–‡ï¼Œè¼¸å‡ºè‡³ {output_file}")
    
    def _write_csv(self, articles: List[Dict[str, Any]], output_file: str):
        """å¯«å…¥CSVæ–‡ä»¶ - ä¸­æ–‡æ¬„ä½åç¨±"""
        # è‹±æ–‡æ¬„ä½åˆ°ä¸­æ–‡æ¬„ä½æ˜ å°„ï¼ˆåƒ…ä¿ç•™éœ€è¦çš„æ¬„ä½ï¼‰
        field_mapping = {
            'law_code': 'æ³•è¦ä»£ç¢¼',
            'law_name': 'æ³•è¦åç¨±', 
            'revision_date_roc': 'ä¿®æ­£æ—¥æœŸï¼ˆæ°‘åœ‹ï¼‰',
            'category': 'æ³•è¦é¡åˆ¥',
            'authority': 'ä¸»ç®¡æ©Ÿé—œ',
            'chapter_no': 'ç« ç¯€ç·¨è™Ÿ',
            'chapter_title': 'ç« ç¯€æ¨™é¡Œ',
            'article_no_main': 'æ¢æ–‡ä¸»è™Ÿ',
            'article_no_sub': 'æ¢æ–‡æ¬¡è™Ÿ',
            'text_full': 'æ¢æ–‡å®Œæ•´å…§å®¹'
        }
        
        # ä½¿ç”¨ä¸­æ–‡æ¬„ä½åç¨±
        fieldnames = [config.name for config in self.columns]
        
        with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            for article in articles:
                row = {}
                for config in self.columns:
                    chinese_name = config.name
                    # åå‘æŸ¥æ‰¾è‹±æ–‡æ¬„ä½å
                    english_name = None
                    for eng, chi in field_mapping.items():
                        if chi == chinese_name:
                            english_name = eng
                            break
                    
                    if english_name:
                        # ä¸€èˆ¬æ¬„ä½
                        row[chinese_name] = article.get(english_name, config.default_value or '')
                    else:
                        row[chinese_name] = config.default_value or ''
                
                writer.writerow(row)
        
        logger.info(f"CSVè¼¸å‡ºå®Œæˆ - ä½¿ç”¨ä¸­æ–‡æ¬„ä½åç¨±")
        logger.info(f"è¼¸å‡ºæ¬„ä½: {', '.join(fieldnames)}")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ”§ æ³•è¦æ¢æ–‡è½‰æ›å™¨ - ä¸­æ–‡æ¬„ä½ï¼Œè‡ªå‹•æ“´å±•")
    print("=" * 50)
    
    # å»ºç«‹è½‰æ›å™¨
    converter = LawArticleConverter()
    
    # è½‰æ›æ³•è¦æ–‡ä»¶
    output_file = "results/law_articles.csv"
    converter.convert_to_csv("results/mineru_batch", output_file)
    
    # ç¤ºç¯„ï¼šå‹•æ…‹æ·»åŠ æ–°æ³•è¦
    print("\nğŸ“Š ç¤ºç¯„: å‹•æ…‹æ·»åŠ æ–°æ³•è¦")
    converter.add_law_definition('åœŸåœ°æ³•.md', {
        'law_code': 'LAND-ACT',
        'law_name': 'åœŸåœ°æ³•',
        'revision_date_roc': 'æ°‘åœ‹ 100 å¹´ 06 æœˆ 15 æ—¥',
        'category': 'åœŸåœ°ç®¡ç†',
        'authority': 'å…§æ”¿éƒ¨'
    })
    
    print(f"\nâœ… æ³•è¦æ¢æ–‡è½‰æ›å®Œæˆï¼")
    print(f"ğŸ“ è¼¸å‡ºæ–‡ä»¶: {output_file}")
    print(f"ğŸ“Š ä½¿ç”¨ä¸­æ–‡æ¬„ä½åç¨±ï¼Œå¯ç›´æ¥åŒ¯å…¥ä¸­æ–‡è³‡æ–™åº«")
    
    # å±•ç¤ºæ¬„ä½é…ç½®
    print(f"\nğŸ”— è¼¸å‡ºæ¬„ä½ ({len(converter.columns)}å€‹):")
    for i, config in enumerate(converter.columns, 1):
        print(f"   {i:2d}. {config.name}")
    
    print(f"\nğŸš€ åŠŸèƒ½ç‰¹è‰²:")
    print(f"   âœ… ä¸­æ–‡æ¬„ä½åç¨±")
    print(f"   âœ… ç²¾ç°¡æ¬„ä½è¨­è¨ˆ") 
    print(f"   âœ… è‡ªå‹•æª¢æ¸¬æ³•è¦è³‡è¨Š")
    print(f"   âœ… å‹•æ…‹æ·»åŠ æ–°æ³•è¦")
    print(f"   âœ… æ™ºèƒ½ä»£ç¢¼ç”Ÿæˆ")
    print(f"   âœ… å®Œå…¨ä¸­æ–‡åŒ–ç•Œé¢")

if __name__ == "__main__":
    main()
