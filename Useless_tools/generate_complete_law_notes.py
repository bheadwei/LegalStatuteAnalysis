#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´æ³•æ¢è¤‡ç¿’ç­†è¨˜ç”Ÿæˆå™¨
æŒ‰æ³•è¦åˆ†åˆ¥ç”Ÿæˆå®Œæ•´çš„ç­†è¨˜æª”æ¡ˆï¼ŒåŒ…å«æ‰€æœ‰æ¢æ–‡å’Œç›¸é—œè€ƒé¡Œ
"""

import json
import pandas as pd
from pathlib import Path
from typing import Dict, List, Any, Set
from collections import defaultdict
import re

PROJECT_ROOT = Path(__file__).parent.parent

class CompleteLawNotesGenerator:
    """å®Œæ•´æ³•æ¢è¤‡ç¿’ç­†è¨˜ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.law_articles = {}  # æ³•æ¢è³‡æ–™
        self.exam_results = {}  # è€ƒé¡Œçµæœ
        self.law_question_mapping = defaultdict(list)  # æ³•æ¢ -> è€ƒé¡Œæ˜ å°„
        self.law_groups = defaultdict(list)  # æŒ‰æ³•è¦åˆ†çµ„
        
    def load_data(self):
        """è¼‰å…¥æ‰€æœ‰è³‡æ–™"""
        print("ğŸ“Š è¼‰å…¥æ³•æ¢è³‡æ–™...")
        self._load_law_articles()
        
        print("ğŸ“ è¼‰å…¥è€ƒé¡Œçµæœ...")
        self._load_exam_results()
        
        print("ğŸ”— å»ºç«‹æ³•æ¢-è€ƒé¡Œé—œè¯...")
        self._build_law_question_mapping()
        
        print("ğŸ“‚ å»ºç«‹æ³•è¦åˆ†çµ„...")
        self._build_law_groups()
        
    def _load_law_articles(self):
        """è¼‰å…¥æ³•æ¢è³‡æ–™"""
        csv_path = PROJECT_ROOT / "results" / "law_articles.csv"
        df = pd.read_csv(csv_path, encoding='utf-8')
        
        for _, row in df.iterrows():
            article_id = f"{row['æ³•è¦ä»£ç¢¼']}-{row['æ¢æ–‡ä¸»è™Ÿ']}"
            if row['æ¢æ–‡æ¬¡è™Ÿ'] > 0:
                article_id += f"-{row['æ¢æ–‡æ¬¡è™Ÿ']}"
            
            self.law_articles[article_id] = {
                "law_code": row['æ³•è¦ä»£ç¢¼'],
                "law_name": row['æ³•è¦åç¨±'],
                "chapter_no": row['ç« ç¯€ç·¨è™Ÿ'],
                "chapter_title": row['ç« ç¯€æ¨™é¡Œ'],
                "article_no_main": row['æ¢æ–‡ä¸»è™Ÿ'],
                "article_no_sub": row['æ¢æ–‡æ¬¡è™Ÿ'],
                "article_title": row.get('æ¢æ–‡æ¨™é¡Œ', ''),
                "content": row['æ¢æ–‡å®Œæ•´å…§å®¹'],
                "category": row.get('æ³•è¦é¡åˆ¥', ''),
                "authority": row.get('ä¸»ç®¡æ©Ÿé—œ', ''),
                "revision_date": row.get('ä¿®æ­£æ—¥æœŸï¼ˆæ°‘åœ‹ï¼‰', '')
            }
    
    def _load_exam_results(self):
        """è¼‰å…¥è€ƒé¡Œçµæœ"""
        results_path = PROJECT_ROOT / "results" / "core_embedding_enhanced_format.json"
        
        with open(results_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        self.exam_results = data
    
    def _build_law_question_mapping(self):
        """å»ºç«‹æ³•æ¢èˆ‡è€ƒé¡Œçš„é—œè¯"""
        questions = self.exam_results.get('questions', [])
        
        for question in questions:
            q_num = question['question_number']
            
            # è™•ç†é¡Œç›®æœ¬èº«çš„æ³•æ¢åŒ¹é…
            question_law_match = self._extract_law_reference(question['content'][1])
            if question_law_match:
                self.law_question_mapping[question_law_match].append({
                    'type': 'question',
                    'question_number': q_num,
                    'content': question['content'][0],
                    'correct_answer': question['correct_answer'],
                    'points': question['points'],
                    'options': question['options']
                })
            
            # è™•ç†å„é¸é …çš„æ³•æ¢åŒ¹é…
            for option_letter, option_data in question['options'].items():
                option_content = option_data[0]
                option_law_match = self._extract_law_reference(option_data[1])
                
                if option_law_match:
                    is_correct = (option_letter == question['correct_answer'])
                    
                    self.law_question_mapping[option_law_match].append({
                        'type': 'option',
                        'question_number': q_num,
                        'option_letter': option_letter,
                        'option_content': option_content,
                        'is_correct': is_correct,
                        'question_content': question['content'][0],
                        'all_options': question['options'],
                        'correct_answer': question['correct_answer'],
                        'points': question['points'],
                        'law_reference': option_data[1]
                    })
    
    def _extract_law_reference(self, match_text: str) -> str:
        """å¾åŒ¹é…æ–‡å­—ä¸­æå–æ³•æ¢ä»£ç¢¼"""
        if not match_text or 'ç¬¬' not in match_text or 'æ¢' not in match_text:
            return None
        
        # æ ¹æ“šæ³•è¦åç¨±å°æ‡‰ä»£ç¢¼ (å¿…é ˆèˆ‡ CSV ä¸­çš„æ³•è¦ä»£ç¢¼å®Œå…¨ä¸€è‡´)
        law_name_mapping = {
            'ä¸å‹•ç”¢ç¶“ç´€æ¥­ç®¡ç†æ¢ä¾‹': 'REA-ACT',
            'ä¸å‹•ç”¢ç¶“ç´€æ¥­ç®¡ç†æ¢ä¾‹æ–½è¡Œç´°å‰‡': 'REA-RULES', 
            'å…¬å¯“å¤§å»ˆç®¡ç†æ¢ä¾‹': 'CMCA',
            'æ¶ˆè²»è€…ä¿è­·æ³•': 'CPA',
            'å…¬å¹³äº¤æ˜“æ³•': 'FTA'
        }
        
        # æ‰¾å‡ºæ³•è¦åç¨±å’Œæ¢è™Ÿ
        for law_name, law_code in law_name_mapping.items():
            if law_name in match_text:
                # æå–æ¢è™Ÿ
                match = re.search(r'ç¬¬(\d+)æ¢', match_text)
                if match:
                    article_no = match.group(1)
                    return f"{law_code}-{article_no}"
        
        return None
    
    def _build_law_groups(self):
        """å»ºç«‹æ³•è¦åˆ†çµ„"""
        for article_id, article_data in self.law_articles.items():
            law_name = article_data['law_name']
            self.law_groups[law_name].append((article_id, article_data))
        
        # æŒ‰æ¢è™Ÿæ’åº
        for law_name in self.law_groups:
            self.law_groups[law_name].sort(key=lambda x: (x[1]['chapter_no'], x[1]['article_no_main'], x[1]['article_no_sub']))
    
    def generate_all_notes(self):
        """ç”Ÿæˆæ‰€æœ‰æ³•è¦çš„ç­†è¨˜"""
        print("ğŸ“ é–‹å§‹ç”Ÿæˆå®Œæ•´æ³•æ¢ç­†è¨˜...")
        
        notes_dir = PROJECT_ROOT / "results" / "æ³•æ¢ç­†è¨˜"
        notes_dir.mkdir(exist_ok=True)
        
        for law_name in sorted(self.law_groups.keys()):
            output_path = notes_dir / f"{law_name}_è¤‡ç¿’ç­†è¨˜.md"
            self._generate_law_note(law_name, str(output_path))
        
        # ç”Ÿæˆç¸½è¦½æª”æ¡ˆ
        self._generate_overview(notes_dir / "æ³•æ¢è¤‡ç¿’ç­†è¨˜ç¸½è¦½.md")
        
        print(f"âœ… æ‰€æœ‰ç­†è¨˜å·²ç”Ÿæˆå®Œæˆ: {notes_dir}")
    
    def _generate_law_note(self, law_name: str, output_path: str):
        """ç”Ÿæˆå–®ä¸€æ³•è¦çš„ç­†è¨˜"""
        articles = self.law_groups[law_name]
        
        # å–å¾—è€ƒè©¦åŸºæœ¬è³‡è¨Š
        metadata = self.exam_results.get('metadata', {})
        exam_year = self._extract_year_from_title(metadata.get('exam_title', ''))
        course_name = metadata.get('course_name', '')
        
        markdown_content = self._generate_law_header(law_name, exam_year, course_name)
        
        # æŒ‰ç« ç¯€åˆ†çµ„
        chapter_groups = defaultdict(list)
        for article_id, article_data in articles:
            chapter_key = (article_data['chapter_no'], article_data['chapter_title'])
            chapter_groups[chapter_key].append((article_id, article_data))
        
        # ç”Ÿæˆå„ç« ç¯€å…§å®¹
        for chapter_key in sorted(chapter_groups.keys()):
            chapter_no, chapter_title = chapter_key
            chapter_articles = chapter_groups[chapter_key]
            markdown_content += self._generate_chapter_section(chapter_no, chapter_title, chapter_articles, exam_year, course_name)
        
        # ç”Ÿæˆçµ±è¨ˆè³‡è¨Š
        markdown_content += self._generate_law_statistics(law_name, articles)
        
        # å„²å­˜æª”æ¡ˆ
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        print(f"ğŸ“„ å·²ç”Ÿæˆ: {law_name}_è¤‡ç¿’ç­†è¨˜.md")
    
    def _generate_law_header(self, law_name: str, exam_year: str, course_name: str) -> str:
        """ç”Ÿæˆæ³•è¦ç­†è¨˜æ¨™é¡Œ"""
        metadata = self.exam_results.get('metadata', {})
        
        header = f"""# ğŸ“š {law_name} è¤‡ç¿’ç­†è¨˜

## ğŸ“‹ åŸºæœ¬è³‡è¨Š
- **æ³•è¦åç¨±**: {law_name}
- **è€ƒè©¦å¹´åº¦**: {exam_year}
- **è€ƒè©¦ç§‘ç›®**: {course_name}
- **åˆ†ææ™‚é–“**: {metadata.get('timestamp', '')}
- **åˆ†ææ¨¡å‹**: {metadata.get('embedding_model', '')}

---

## ğŸ“– ä½¿ç”¨èªªæ˜

æœ¬ç­†è¨˜åŒ…å« **{law_name}** çš„å®Œæ•´æ¢æ–‡å…§å®¹åŠç›¸é—œè€ƒé¡Œï¼š

- ğŸ¯ **å®Œæ•´æ¢æ–‡**: åŒ…å«æ‰€æœ‰æ¢æ–‡ï¼Œä¸è«–æ˜¯å¦æœ‰è€ƒé¡Œå°æ‡‰
- âœ… **æ­£ç¢ºé¸é …**: æ¨™ç¤ºç‚ºæ­£ç¢ºç­”æ¡ˆçš„é¸é …
- âŒ **éŒ¯èª¤é¸é …**: æ¨™ç¤ºç‚ºéŒ¯èª¤ç­”æ¡ˆçš„é¸é …
- ğŸ“ **è€ƒé¡Œæ¨™ç±¤**: æ¨™ç¤ºå¹´ä»½å’Œç§‘ç›®
- ğŸ”— **æ³•æ¢å¼•ç”¨**: å„é¸é …åƒç…§çš„æ³•æ¢å‡ºè™•

---

"""
        return header
    
    def _generate_chapter_section(self, chapter_no: int, chapter_title: str, articles: List[tuple], exam_year: str, course_name: str) -> str:
        """ç”Ÿæˆç« ç¯€å…§å®¹"""
        content = f"\n## ğŸ“– ç¬¬{chapter_no}ç«  {chapter_title}\n\n"
        
        for article_id, article_data in articles:
            content += self._generate_article_section(article_id, article_data, exam_year, course_name)
        
        return content
    
    def _generate_article_section(self, article_id: str, article_data: Dict, exam_year: str, course_name: str) -> str:
        """ç”Ÿæˆå–®ä¸€æ³•æ¢çš„å®Œæ•´ç« ç¯€"""
        article_no = article_data['article_no_main']
        if article_data['article_no_sub'] > 0:
            article_no = f"{article_no}-{article_data['article_no_sub']}"
        
        content = f"\n### ğŸ“‹ ç¬¬ {article_no} æ¢"
        
        # åŠ å…¥æ¢æ–‡æ¨™é¡Œï¼ˆå¦‚æœæœ‰ï¼‰
        if article_data.get('article_title') and article_data['article_title'].strip():
            content += f" {article_data['article_title']}"
        
        content += "\n\n"
        
        # æ³•æ¢å…§å®¹
        content += f"**æ¢æ–‡å…§å®¹:**\n\n"
        content += f"> {article_data['content']}\n\n"
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ç›¸é—œè€ƒé¡Œ
        related_questions = self.law_question_mapping.get(article_id, [])
        
        if related_questions:
            content += f"**ğŸ“ ç›¸é—œè€ƒé¡Œ:**\n\n"
            content += self._generate_related_questions(related_questions, exam_year, course_name)
        else:
            content += f"**ğŸ“ ç›¸é—œè€ƒé¡Œ:**\n\n"
            content += f"ğŸ”¸ **ç„¡å°æ‡‰è€ƒé¡Œ**\n\n"
        
        content += "---\n\n"
        return content
    
    def _generate_related_questions(self, related_questions: List[Dict], exam_year: str, course_name: str) -> str:
        """ç”Ÿæˆç›¸é—œè€ƒé¡Œå…§å®¹"""
        content = ""
        
        # æŒ‰é¡Œè™Ÿåˆ†çµ„
        question_groups = defaultdict(list)
        for item in related_questions:
            question_groups[item['question_number']].append(item)
        
        for q_num in sorted(question_groups.keys()):
            items = question_groups[q_num]
            content += self._generate_complete_question(q_num, items, exam_year, course_name)
        
        return content
    
    def _generate_complete_question(self, q_num: int, items: List[Dict], exam_year: str, course_name: str) -> str:
        """ç”Ÿæˆå®Œæ•´é¡Œç›®å…§å®¹"""
        content = f"\n#### ğŸ¯ ç¬¬ {q_num} é¡Œ `{exam_year}å¹´ {course_name}`\n\n"
        
        # å–å¾—å®Œæ•´é¡Œç›®è³‡è¨Š
        question_item = None
        option_items = []
        
        for item in items:
            if item['type'] == 'question':
                question_item = item
            else:
                option_items.append(item)
        
        # å¦‚æœæ²’æœ‰question_itemï¼Œå¾option_itemä¸­å–å¾—å®Œæ•´è³‡è¨Š
        if not question_item and option_items:
            first_option = option_items[0]
            question_content = first_option['question_content']
            all_options = first_option['all_options']
            correct_answer = first_option['correct_answer']
            points = first_option['points']
        else:
            question_content = question_item['content']
            all_options = question_item['options']
            correct_answer = question_item['correct_answer']
            points = question_item['points']
        
        # é¡¯ç¤ºé¡Œç›®
        content += f"**é¡Œç›®:**\n{question_content}\n\n"
        
        # é¡¯ç¤ºæ‰€æœ‰é¸é …
        content += f"**é¸é …:**\n\n"
        for option_letter in ['A', 'B', 'C', 'D']:
            if option_letter in all_options:
                option_text = all_options[option_letter][0]
                option_law_ref = all_options[option_letter][1]
                
                # åˆ¤æ–·æ˜¯å¦ç‚ºæ­£ç¢ºç­”æ¡ˆ
                status_icon = "âœ…" if option_letter == correct_answer else "âŒ"
                
                content += f"- **{option_letter}** {status_icon}: {option_text}\n"
                content += f"  - ğŸ“– *åƒç…§æ³•æ¢: {option_law_ref}*\n\n"
        
        content += f"**âœ… æ­£ç¢ºç­”æ¡ˆ:** {correct_answer} ({points} åˆ†)\n\n"
        
        # æ¨™ç¤ºæœ¬æ¢æ–‡åœ¨æ­¤é¡Œä¸­çš„é—œè¯æ€§
        related_options = [item for item in option_items if item['question_number'] == q_num]
        if related_options:
            content += f"**ğŸ”— æœ¬æ¢æ–‡é—œè¯:**\n"
            for item in related_options:
                status = "æ­£ç¢ºç­”æ¡ˆ" if item['is_correct'] else "éŒ¯èª¤é¸é …"
                content += f"- é¸é … {item['option_letter']} ({status}): {item['option_content'][:50]}...\n"
            content += "\n"
        
        return content
    
    def _generate_law_statistics(self, law_name: str, articles: List[tuple]) -> str:
        """ç”Ÿæˆæ³•è¦çµ±è¨ˆè³‡è¨Š"""
        content = "\n## ğŸ“Š çµ±è¨ˆè³‡è¨Š\n\n"
        
        # è¨ˆç®—æœ‰è€ƒé¡Œé—œè¯çš„æ³•æ¢æ•¸é‡
        related_count = 0
        total_count = len(articles)
        
        for article_id, _ in articles:
            if article_id in self.law_question_mapping:
                related_count += 1
        
        content += f"**æ¢æ–‡çµ±è¨ˆ:**\n"
        content += f"- ç¸½æ¢æ–‡æ•¸: {total_count} æ¢\n"
        content += f"- æœ‰è€ƒé¡Œé—œè¯: {related_count} æ¢\n"
        content += f"- é—œè¯æ¯”ä¾‹: {related_count/total_count*100:.1f}%\n\n"
        
        # ç« ç¯€çµ±è¨ˆ
        chapter_stats = defaultdict(int)
        chapter_related_stats = defaultdict(int)
        
        for article_id, article_data in articles:
            chapter_title = article_data['chapter_title']
            chapter_stats[chapter_title] += 1
            if article_id in self.law_question_mapping:
                chapter_related_stats[chapter_title] += 1
        
        content += f"**ç« ç¯€çµ±è¨ˆ:**\n"
        for chapter_title in sorted(chapter_stats.keys()):
            total = chapter_stats[chapter_title]
            related = chapter_related_stats.get(chapter_title, 0)
            percentage = related/total*100 if total > 0 else 0
            content += f"- {chapter_title}: {related}/{total} æ¢ ({percentage:.1f}%)\n"
        
        return content
    
    def _generate_overview(self, output_path: str):
        """ç”Ÿæˆç¸½è¦½æª”æ¡ˆ"""
        metadata = self.exam_results.get('metadata', {})
        exam_year = self._extract_year_from_title(metadata.get('exam_title', ''))
        
        content = f"""# ğŸ“š {exam_year}å¹´ä¸å‹•ç”¢ç¶“ç´€ç›¸é—œæ³•è¦ è¤‡ç¿’ç­†è¨˜ç¸½è¦½

## ğŸ“‹ è€ƒè©¦è³‡è¨Š
- **è€ƒè©¦åç¨±**: {metadata.get('exam_title', '')}
- **ç§‘ç›®åç¨±**: {metadata.get('course_name', '')}
- **è€ƒè©¦æ™‚é–“**: {metadata.get('exam_duration', '')}
- **åˆ†ææ™‚é–“**: {metadata.get('timestamp', '')}

---

## ğŸ“– æ³•è¦åˆ—è¡¨

"""
        
        for law_name in sorted(self.law_groups.keys()):
            articles = self.law_groups[law_name]
            related_count = sum(1 for article_id, _ in articles if article_id in self.law_question_mapping)
            total_count = len(articles)
            percentage = related_count/total_count*100 if total_count > 0 else 0
            
            content += f"### ğŸ“– [{law_name}](./{law_name}_è¤‡ç¿’ç­†è¨˜.md)\n\n"
            content += f"- **ç¸½æ¢æ–‡æ•¸**: {total_count} æ¢\n"
            content += f"- **æœ‰è€ƒé¡Œé—œè¯**: {related_count} æ¢ ({percentage:.1f}%)\n"
            content += f"- **ç­†è¨˜æª”æ¡ˆ**: `{law_name}_è¤‡ç¿’ç­†è¨˜.md`\n\n"
        
        # æ•´é«”çµ±è¨ˆ
        total_articles = len(self.law_articles)
        total_related = len(self.law_question_mapping)
        overall_percentage = total_related/total_articles*100 if total_articles > 0 else 0
        
        content += f"""
## ğŸ“Š æ•´é«”çµ±è¨ˆ

- **æ³•è¦æ•¸é‡**: {len(self.law_groups)} éƒ¨
- **ç¸½æ¢æ–‡æ•¸**: {total_articles} æ¢
- **æœ‰è€ƒé¡Œé—œè¯**: {total_related} æ¢
- **æ•´é«”é—œè¯æ¯”ä¾‹**: {overall_percentage:.1f}%
- **è€ƒé¡Œç¸½æ•¸**: {metadata.get('total_questions', 0)} é¡Œ

---

## ğŸ¯ ä½¿ç”¨å»ºè­°

1. **æŒ‰æ³•è¦è¤‡ç¿’**: é»æ“Šä¸Šæ–¹é€£çµé€²å…¥å„æ³•è¦çš„å®Œæ•´ç­†è¨˜
2. **é‡é»æ¢æ–‡**: å„ªå…ˆè¤‡ç¿’æœ‰è€ƒé¡Œé—œè¯çš„æ¢æ–‡
3. **å®Œæ•´å­¸ç¿’**: æ‰€æœ‰æ¢æ–‡éƒ½å·²åŒ…å«ï¼Œå»ºè­°å®Œæ•´é–±è®€
4. **è€ƒé¡Œç·´ç¿’**: æ¯æ¢æœ‰é—œè¯çš„æ³•æ¢éƒ½é™„æœ‰å®Œæ•´è€ƒé¡Œ

"""
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"ğŸ“„ å·²ç”Ÿæˆç¸½è¦½: æ³•æ¢è¤‡ç¿’ç­†è¨˜ç¸½è¦½.md")
    
    def _extract_year_from_title(self, title: str) -> str:
        """å¾è€ƒè©¦æ¨™é¡Œä¸­æå–å¹´ä»½"""
        match = re.search(r'(\d{3})å¹´', title)
        return match.group(1) if match else "113"

def main():
    """ä¸»ç¨‹å¼"""
    print("ğŸ“š å®Œæ•´æ³•æ¢è¤‡ç¿’ç­†è¨˜ç”Ÿæˆå™¨")
    print("=" * 50)
    
    try:
        # å»ºç«‹ç”Ÿæˆå™¨
        generator = CompleteLawNotesGenerator()
        
        # è¼‰å…¥è³‡æ–™
        generator.load_data()
        
        # ç”Ÿæˆæ‰€æœ‰ç­†è¨˜
        generator.generate_all_notes()
        
        print(f"\nğŸ‰ æ‰€æœ‰ç­†è¨˜ç”Ÿæˆå®Œæˆï¼")
        
        # é¡¯ç¤ºçµ±è¨ˆ
        total_laws = len(generator.law_groups)
        total_articles = len(generator.law_articles)
        related_articles = len(generator.law_question_mapping)
        
        print(f"ğŸ“Š ç”Ÿæˆçµ±è¨ˆ:")
        print(f"   - æ³•è¦æ•¸é‡: {total_laws} éƒ¨")
        print(f"   - ç¸½æ¢æ–‡æ•¸: {total_articles} æ¢")
        print(f"   - æœ‰è€ƒé¡Œé—œè¯: {related_articles} æ¢")
        print(f"   - é—œè¯æ¯”ä¾‹: {related_articles/total_articles*100:.1f}%")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±æ•—: {e}")
        raise

if __name__ == "__main__":
    main()
