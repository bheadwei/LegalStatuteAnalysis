#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡å¤„ç†è€ƒå·å’Œç­”æ¡ˆPDFæ–‡ä»¶
è‡ªåŠ¨å°†è€ƒå·PDFå’Œç­”æ¡ˆPDFé…å¯¹ï¼Œè½¬æ¢ä¸ºMarkdownï¼Œç„¶ååˆå¹¶æˆJSONæ ¼å¼

ä½¿ç”¨æ–¹æ³•:
    poetry run python scripts/batch_process_exams.py --data-dir data --output-dir results

åŠŸèƒ½:
    1. è‡ªåŠ¨è¯†åˆ«dataç›®å½•ä¸‹çš„è€ƒå·å’Œç­”æ¡ˆPDFå¯¹
    2. ä½¿ç”¨PDFè½¬æ¢å™¨å°†PDFè½¬æ¢ä¸ºMarkdown
    3. ä½¿ç”¨LLMè§£æå™¨è§£æè€ƒé¢˜å’Œç­”æ¡ˆ
    4. åˆå¹¶æˆJSONæ ¼å¼å¹¶ä¿å­˜
"""

import argparse
import json
import logging
from pathlib import Path
import sys
from typing import Dict, List, Tuple
import re

# Add project root to sys.path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn
from rich.table import Table
from rich import print as rprint

from src.pdf_converter.core import PDFToMarkdownConverter
from src.parsing.llm_parser import (
    parse_questions_with_llm,
    parse_answers_with_llm,
    merge_qa_json,
)

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
console = Console()


def find_exam_pairs(data_dir: Path) -> List[Tuple[Path, Path, str]]:
    """
    æŸ¥æ‰¾dataç›®å½•ä¸‹çš„è€ƒå·å’Œç­”æ¡ˆPDFå¯¹
    æ”¯æ´å¾ questions/ å’Œ answer/ å­ç›®éŒ„è®€å–

    è¿”å›: List of (question_pdf, answer_pdf, exam_name)
    """
    # æª¢æŸ¥æ˜¯å¦æœ‰ questions å’Œ answer å­ç›®éŒ„
    questions_dir = data_dir / "questions"
    answers_dir = data_dir / "answer"

    # å¦‚æœå­ç›®éŒ„å­˜åœ¨ï¼Œä½¿ç”¨å­ç›®éŒ„ï¼›å¦å‰‡ä½¿ç”¨æ ¹ç›®éŒ„
    if questions_dir.exists() and answers_dir.exists():
        logger.info(f"æª¢æ¸¬åˆ°å­ç›®éŒ„çµæ§‹ï¼Œä½¿ç”¨ {questions_dir} å’Œ {answers_dir}")
        question_search_dir = questions_dir
        answer_search_dir = answers_dir
    else:
        logger.info(f"ä½¿ç”¨å–®ä¸€ç›®éŒ„: {data_dir}")
        question_search_dir = data_dir
        answer_search_dir = data_dir

    exam_pairs = []

    # è·å–æ‰€æœ‰è€ƒé¢˜PDF
    pdf_files = list(question_search_dir.glob("*.pdf"))

    # è¯†åˆ«è€ƒå·PDFï¼ˆä¸å«ANSçš„ï¼‰
    question_pdfs = [f for f in pdf_files if "ANS" not in f.name]

    for question_pdf in question_pdfs:
        # ä»æ–‡ä»¶åæå–è€ƒè¯•ä»£ç ï¼Œä¾‹å¦‚ "112190_1201_æ°‘æ³•æ¦‚è¦.pdf" -> "112190_1201"
        match = re.match(r"(\d+_\d+)_(.+)\.pdf$", question_pdf.name)
        if not match:
            logger.warning(f"æ— æ³•è§£ææ–‡ä»¶åæ ¼å¼: {question_pdf.name}")
            continue

        exam_code = match.group(1)  # "112190_1201"
        exam_subject = match.group(2)  # "æ°‘æ³•æ¦‚è¦"

        # æŸ¥æ‰¾å¯¹åº”çš„ç­”æ¡ˆPDF
        answer_pdf = answer_search_dir / f"{exam_code.split('_')[0]}_ANS{exam_code.split('_')[1]}_{exam_subject}.pdf"

        if answer_pdf.exists():
            exam_pairs.append((question_pdf, answer_pdf, f"{exam_code}_{exam_subject}"))
        else:
            logger.warning(f"æ‰¾ä¸åˆ°å¯¹åº”çš„ç­”æ¡ˆPDF: {answer_pdf.name}")

    return exam_pairs


def convert_pdf_to_markdown(pdf_path: Path, output_path: Path, use_gpu: bool = True) -> str:
    """
    å°†PDFè½¬æ¢ä¸ºMarkdown

    è¿”å›: Markdownå†…å®¹
    """
    try:
        converter = PDFToMarkdownConverter(logger)
        markdown_content = converter.process_pdf(pdf_path, output_path, use_gpu=use_gpu)
        return markdown_content
    except Exception as e:
        logger.error(f"PDFè½¬æ¢å¤±è´¥ {pdf_path.name}: {e}")
        raise


def process_exam_pair(
    question_pdf: Path,
    answer_pdf: Path,
    exam_name: str,
    markdown_dir: Path,
    output_dir: Path,
    skip_pdf_conversion: bool = False,
    use_gpu: bool = True
) -> Dict:
    """
    å¤„ç†ä¸€å¯¹è€ƒå·å’Œç­”æ¡ˆ

    è¿”å›: å¤„ç†ç»“æœå­—å…¸
    """
    result = {
        "exam_name": exam_name,
        "question_pdf": str(question_pdf),
        "answer_pdf": str(answer_pdf),
        "status": "pending"
    }

    try:
        # 1. è®¾ç½®Markdownæ–‡ä»¶è·¯å¾„
        question_md = markdown_dir / f"{question_pdf.stem}.md"
        answer_md = markdown_dir / f"{answer_pdf.stem}.md"

        # 2. è½¬æ¢PDFåˆ°Markdownï¼ˆå¦‚æœéœ€è¦ï¼‰
        if skip_pdf_conversion and question_md.exists() and answer_md.exists():
            logger.info(f"è·³è¿‡PDFè½¬æ¢ï¼Œä½¿ç”¨ç°æœ‰Markdownæ–‡ä»¶")
            question_content = question_md.read_text(encoding="utf-8")
            answer_content = answer_md.read_text(encoding="utf-8")
        else:
            logger.info(f"è½¬æ¢è€ƒå·PDF: {question_pdf.name}")
            question_content = convert_pdf_to_markdown(question_pdf, question_md, use_gpu)

            logger.info(f"è½¬æ¢ç­”æ¡ˆPDF: {answer_pdf.name}")
            answer_content = convert_pdf_to_markdown(answer_pdf, answer_md, use_gpu)

        result["question_md"] = str(question_md)
        result["answer_md"] = str(answer_md)

        # 3. ä½¿ç”¨LLMè§£æè€ƒé¢˜å’Œç­”æ¡ˆ
        logger.info(f"ä½¿ç”¨LLMè§£æè€ƒé¢˜: {exam_name}")
        questions_result = parse_questions_with_llm(question_content)
        if not questions_result:
            raise Exception("è€ƒé¢˜è§£æå¤±è´¥")

        logger.info(f"ä½¿ç”¨LLMè§£æç­”æ¡ˆ: {exam_name}")
        answers_result = parse_answers_with_llm(answer_content)
        if not answers_result:
            raise Exception("ç­”æ¡ˆè§£æå¤±è´¥")

        # 4. åˆå¹¶è€ƒé¢˜å’Œç­”æ¡ˆ
        logger.info(f"åˆå¹¶è€ƒé¢˜å’Œç­”æ¡ˆ: {exam_name}")
        final_json = merge_qa_json(questions_result, answers_result)

        # 5. ä¿å­˜JSONæ–‡ä»¶
        output_file = output_dir / f"{exam_name}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_json, f, ensure_ascii=False, indent=2)

        result["output_json"] = str(output_file)
        result["status"] = "success"
        logger.info(f"æˆåŠŸå¤„ç†: {exam_name} -> {output_file}")

    except Exception as e:
        result["status"] = "failed"
        result["error"] = str(e)
        logger.error(f"å¤„ç†å¤±è´¥ {exam_name}: {e}")

    return result


def main():
    """ä¸»å‡½æ•°"""
    # Load environment variables
    load_dotenv()

    parser = argparse.ArgumentParser(
        description="æ‰¹é‡å¤„ç†è€ƒå·å’Œç­”æ¡ˆPDFï¼Œè½¬æ¢æˆJSONæ ¼å¼",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
    # å¤„ç†æ‰€æœ‰PDFæ–‡ä»¶
    poetry run python scripts/batch_process_exams.py

    # æŒ‡å®šæ•°æ®ç›®å½•å’Œè¾“å‡ºç›®å½•
    poetry run python scripts/batch_process_exams.py --data-dir data --output-dir results/exams

    # è·³è¿‡PDFè½¬æ¢ï¼ˆå¦‚æœå·²æœ‰Markdownæ–‡ä»¶ï¼‰
    poetry run python scripts/batch_process_exams.py --skip-pdf-conversion
        """
    )
    parser.add_argument(
        "--data-dir",
        type=Path,
        default=Path("data"),
        help="åŒ…å«PDFæ–‡ä»¶çš„ç›®å½• (é»˜è®¤: data)"
    )
    parser.add_argument(
        "--markdown-dir",
        type=Path,
        default=Path("results/markdown"),
        help="Markdownæ–‡ä»¶è¾“å‡ºç›®å½• (é»˜è®¤: results/markdown)"
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=Path("results/exams"),
        help="JSONæ–‡ä»¶è¾“å‡ºç›®å½• (é»˜è®¤: results/exams)"
    )
    parser.add_argument(
        "--skip-pdf-conversion",
        action="store_true",
        help="è·³è¿‡PDFè½¬æ¢æ­¥éª¤ï¼ˆå¦‚æœMarkdownæ–‡ä»¶å·²å­˜åœ¨ï¼‰"
    )
    parser.add_argument(
        "--use-gpu",
        action="store_true",
        default=True,
        help="ä½¿ç”¨GPUåŠ é€ŸPDFè½¬æ¢ï¼ˆé»˜è®¤ï¼šå¯ç”¨ï¼‰"
    )
    parser.add_argument(
        "--no-gpu",
        action="store_true",
        help="ç¦ç”¨GPUï¼Œä½¿ç”¨CPUè¿›è¡ŒPDFè½¬æ¢"
    )

    args = parser.parse_args()

    # ç¡®å®šæ˜¯å¦ä½¿ç”¨GPU
    use_gpu = not args.no_gpu if hasattr(args, 'no_gpu') else args.use_gpu

    # åˆ›å»ºè¾“å‡ºç›®å½•
    args.markdown_dir.mkdir(parents=True, exist_ok=True)
    args.output_dir.mkdir(parents=True, exist_ok=True)

    console.print("\n[bold cyan]ğŸ“š è€ƒå·ç­”æ¡ˆæ‰¹é‡å¤„ç†å·¥å…·[/bold cyan]")
    console.print("=" * 60)
    console.print(f"[yellow]âš™ï¸  GPUåŠ é€Ÿ:[/yellow] {'å¯ç”¨' if use_gpu else 'ç¦ç”¨'}")

    # 1. æŸ¥æ‰¾è€ƒå·ç­”æ¡ˆå¯¹
    console.print(f"\n[yellow]ğŸ” æ‰«æç›®å½•:[/yellow] {args.data_dir}")
    exam_pairs = find_exam_pairs(args.data_dir)

    if not exam_pairs:
        console.print("[red]âŒ æœªæ‰¾åˆ°è€ƒå·å’Œç­”æ¡ˆPDFå¯¹ï¼[/red]")
        console.print("\n[yellow]æç¤ºï¼š[/yellow]")
        console.print("  - è€ƒå·æ–‡ä»¶æ ¼å¼: 112190_1201_æ°‘æ³•æ¦‚è¦.pdf")
        console.print("  - ç­”æ¡ˆæ–‡ä»¶æ ¼å¼: 112190_ANS1201_æ°‘æ³•æ¦‚è¦.pdf")
        return

    # æ˜¾ç¤ºæ‰¾åˆ°çš„æ–‡ä»¶å¯¹
    table = Table(title=f"æ‰¾åˆ° {len(exam_pairs)} å¯¹è€ƒå·ç­”æ¡ˆ")
    table.add_column("åºå·", style="cyan", width=6)
    table.add_column("è€ƒè¯•ç§‘ç›®", style="green")
    table.add_column("è€ƒå·æ–‡ä»¶", style="yellow")
    table.add_column("ç­”æ¡ˆæ–‡ä»¶", style="magenta")

    for idx, (q_pdf, a_pdf, exam_name) in enumerate(exam_pairs, 1):
        table.add_row(
            str(idx),
            exam_name.split('_', 2)[-1],  # æå–ç§‘ç›®å
            q_pdf.name,
            a_pdf.name
        )

    console.print(table)

    # 2. å¤„ç†æ¯ä¸€å¯¹è€ƒå·ç­”æ¡ˆ
    console.print(f"\n[yellow]ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†...[/yellow]")
    results = []

    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TaskProgressColumn(),
        console=console
    ) as progress:
        task = progress.add_task("[cyan]å¤„ç†ä¸­...", total=len(exam_pairs))

        for question_pdf, answer_pdf, exam_name in exam_pairs:
            progress.update(task, description=f"[cyan]å¤„ç†: {exam_name}")

            result = process_exam_pair(
                question_pdf,
                answer_pdf,
                exam_name,
                args.markdown_dir,
                args.output_dir,
                args.skip_pdf_conversion,
                use_gpu
            )
            results.append(result)

            progress.advance(task)

    # 3. æ˜¾ç¤ºå¤„ç†ç»“æœ
    console.print("\n[bold green]âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼[/bold green]")
    console.print("=" * 60)

    success_count = len([r for r in results if r["status"] == "success"])
    failed_count = len([r for r in results if r["status"] == "failed"])

    # ç»Ÿè®¡è¡¨
    stats_table = Table(title="å¤„ç†ç»Ÿè®¡")
    stats_table.add_column("é¡¹ç›®", style="cyan")
    stats_table.add_column("æ•°é‡", style="magenta", justify="right")
    stats_table.add_row("æ€»æ•°", str(len(results)))
    stats_table.add_row("æˆåŠŸ", f"[green]{success_count}[/green]")
    stats_table.add_row("å¤±è´¥", f"[red]{failed_count}[/red]")
    console.print(stats_table)

    # è¯¦ç»†ç»“æœè¡¨
    result_table = Table(title="è¯¦ç»†ç»“æœ")
    result_table.add_column("åºå·", style="cyan", width=6)
    result_table.add_column("è€ƒè¯•ç§‘ç›®", style="green")
    result_table.add_column("çŠ¶æ€", style="yellow")
    result_table.add_column("è¾“å‡ºæ–‡ä»¶", style="magenta")

    for idx, result in enumerate(results, 1):
        subject = result["exam_name"].split('_', 2)[-1]

        if result["status"] == "success":
            status_text = "[green]âœ“ æˆåŠŸ[/green]"
            output = Path(result["output_json"]).name
        else:
            status_text = f"[red]âœ— å¤±è´¥[/red]"
            output = result.get("error", "æœªçŸ¥é”™è¯¯")[:40]

        result_table.add_row(str(idx), subject, status_text, output)

    console.print(result_table)

    # ä¿å­˜å¤„ç†æŠ¥å‘Š
    report_file = args.output_dir / "processing_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump({
            "total": len(results),
            "success": success_count,
            "failed": failed_count,
            "results": results
        }, f, ensure_ascii=False, indent=2)

    console.print(f"\n[cyan]ğŸ“„ å¤„ç†æŠ¥å‘Šå·²ä¿å­˜åˆ°:[/cyan] {report_file}")

    if success_count > 0:
        console.print(f"\n[green]âœ“ JSONæ–‡ä»¶å·²ä¿å­˜åˆ°:[/green] {args.output_dir}")
        console.print(f"[green]âœ“ Markdownæ–‡ä»¶å·²ä¿å­˜åˆ°:[/green] {args.markdown_dir}")


if __name__ == "__main__":
    main()
