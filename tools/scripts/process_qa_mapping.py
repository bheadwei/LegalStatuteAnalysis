"""
é¡Œç›®ç­”æ¡ˆ Mapping è…³æœ¬
è™•ç†ã€Œä¹™éƒ¨åˆ† å–®ä¸€é¸æ“‡é¡Œã€èˆ‡ç­”æ¡ˆè¡¨æ ¼çš„å°æ‡‰
ä½¿ç”¨ LLM æ™ºèƒ½è§£æé¡Œç›®ï¼Œé¿å…æ¼é¡Œå•é¡Œ
"""

import re
import json
import logging
from pathlib import Path
from typing import Dict, List, Tuple
import sys

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from dotenv import load_dotenv
from src.pdf_converter.core import PDFToMarkdownConverter
from src.parsing.llm_parser import parse_questions_with_llm, parse_answers_with_llm

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()


def setup_logger() -> logging.Logger:
    """è¨­ç½®æ—¥èªŒ"""
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    if not logger.handlers:
        handler = logging.StreamHandler()
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
    return logger


def find_matching_answer_file(question_file: Path, answer_dir: Path) -> Path:
    """æ ¹æ“šé¡Œç›®æª”åæ‰¾åˆ°å°æ‡‰çš„ç­”æ¡ˆæª”"""
    # 112190_1201_æ°‘æ³•æ¦‚è¦.pdf -> 112190_ANS1201_æ°‘æ³•æ¦‚è¦.pdf
    match = re.match(r'(\d+)_(\d+)_(.+)\.pdf', question_file.name)
    if not match:
        raise ValueError(f"ç„¡æ³•è§£æé¡Œç›®æª”å: {question_file.name}")

    year_code, subject_code, subject_name = match.groups()
    answer_filename = f'{year_code}_ANS{subject_code}_{subject_name}.pdf'
    answer_path = answer_dir / answer_filename

    if not answer_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°å°æ‡‰ç­”æ¡ˆæª”: {answer_filename}")

    return answer_path


def extract_single_choice_section(markdown_content: str) -> Tuple[str, int]:
    """æå–ã€Œä¹™ã€æ¸¬é©—é¡Œéƒ¨åˆ†ã€å…§å®¹

    Returns:
        (section_content, start_line): æ¸¬é©—é¡Œå…§å®¹å’Œèµ·å§‹è¡Œè™Ÿ
    """
    lines = markdown_content.split('\n')

    # æ‰¾åˆ°ã€Œä¹™ã€æ¸¬é©—é¡Œéƒ¨åˆ†ã€çš„ä½ç½®
    section_start = None
    for i, line in enumerate(lines):
        if 'æ¸¬é©—é¡Œ' in line and ('ä¹™' in line or 'éƒ¨åˆ†' in line):
            section_start = i
            break

    if section_start is None:
        raise ValueError("æœªæ‰¾åˆ°ã€Œæ¸¬é©—é¡Œéƒ¨åˆ†ã€")

    # å¾è©²ä½ç½®é–‹å§‹åˆ°æ–‡ä»¶çµå°¾
    section_content = '\n'.join(lines[section_start:])
    return section_content, section_start


def parse_questions_with_llm_enhanced(markdown_content: str, logger: logging.Logger) -> List[Dict]:
    """ä½¿ç”¨ LLM æ™ºèƒ½è§£æé¸æ“‡é¡Œï¼ˆåƒè€ƒåŸå§‹ç¯„ä¾‹é‚è¼¯ï¼‰

    æ­¤å‡½æ•¸ä½¿ç”¨ LLM ä¾†è§£æé¡Œç›®ï¼Œèƒ½å¤ ï¼š
    1. æ™ºèƒ½åˆ†å‰²é€£åœ¨ä¸€èµ·çš„é¸é …
    2. è™•ç†å„ç¨®æ ¼å¼ç•°å¸¸
    3. ç¢ºä¿ä¸æœƒæ¼é¡Œ

    Returns:
        [
            {
                "question_number": 1,
                "question_text": "é¡Œç›®å…§å®¹",
                "options": {"A": "é¸é …1", "B": "é¸é …2", "C": "é¸é …3", "D": "é¸é …4"}
            },
            ...
        ]
    """
    logger.info("ğŸ“ ä½¿ç”¨ LLM æ™ºèƒ½è§£æé¡Œç›®...")

    try:
        # ä½¿ç”¨ LLM è§£ææ•´ä»½é¡Œç›®æ–‡ä»¶
        parsed_result = parse_questions_with_llm(markdown_content)

        if not parsed_result:
            logger.error("âŒ LLM è§£æå¤±æ•—")
            return []

        # æå–é¸æ“‡é¡Œéƒ¨åˆ†
        mc_section = parsed_result.multiple_choice_section

        questions = []
        for mc_q in mc_section:
            questions.append({
                "question_number": mc_q.question_number,
                "question_text": mc_q.content,
                "options": mc_q.options.dict()  # è½‰æ›ç‚º dict {"A": "...", "B": "...", ...}
            })

        logger.info(f"âœ… LLM æˆåŠŸè§£æ {len(questions)} é¡Œé¸æ“‡é¡Œ")
        return questions

    except Exception as e:
        logger.error(f"âŒ LLM è§£æéç¨‹å‡ºéŒ¯: {e}", exc_info=True)
        return []


def parse_answers_from_table(markdown_content: str, logger: logging.Logger) -> Dict[int, str]:
    """å¾ç­”æ¡ˆè¡¨æ ¼ä¸­æå–ç­”æ¡ˆ

    Returns:
        {1: 'A', 2: 'C', 3: 'B', ...}
    """
    answers = {}

    # æ‰¾åˆ°æ‰€æœ‰è¡¨æ ¼
    table_pattern = r'<table>(.*?)</table>'
    tables = re.findall(table_pattern, markdown_content, re.DOTALL)

    for table in tables:
        # è§£æè¡¨æ ¼ä¸­çš„ã€Œé¡Œè™Ÿã€å’Œã€Œç­”æ¡ˆã€è¡Œ
        # æå–ã€Œç¬¬Né¡Œã€çš„æ¨¡å¼
        question_nums = re.findall(r'ç¬¬(\d+)é¡Œ', table)
        # æå–ç­”æ¡ˆï¼ˆè·³éã€Œé¡Œè™Ÿã€å’Œã€Œç­”æ¡ˆã€ç­‰é—œéµå­—ï¼‰
        answer_row = re.search(r'<tr><td[^>]*>ç­”æ¡ˆ</td>(.+?)</tr>', table)

        if question_nums and answer_row:
            answer_cells = re.findall(r'<td[^>]*>([A-D]?)</td>', answer_row.group(1))

            # é…å°é¡Œè™Ÿå’Œç­”æ¡ˆ
            for q_num_str, ans in zip(question_nums, answer_cells):
                if ans:  # åªè¨˜éŒ„æœ‰ç­”æ¡ˆçš„é¡Œç›®
                    q_num = int(q_num_str)
                    answers[q_num] = ans

    logger.info(f"è§£æåˆ° {len(answers)} å€‹ç­”æ¡ˆ")
    return answers


def merge_questions_and_answers(questions: List[Dict], answers: Dict[int, str]) -> List[Dict]:
    """åˆä½µé¡Œç›®å’Œç­”æ¡ˆ

    Returns:
        [
            {
                "question_number": 1,
                "question_text": "...",
                "options": {"A": "...", "B": "...", "C": "...", "D": "..."},
                "answer": "A",
                "answer_index": 0
            },
            ...
        ]
    """
    merged = []

    for q in questions:
        q_num = q['question_number']
        answer_letter = answers.get(q_num, None)

        if answer_letter:
            # è¨ˆç®—ç­”æ¡ˆç´¢å¼• (A=0, B=1, C=2, D=3)
            answer_index = ord(answer_letter) - ord('A')

            merged.append({
                "question_number": q_num,
                "question_text": q['question_text'],
                "options": q['options'],  # å·²ç¶“æ˜¯ dict æ ¼å¼ {"A": "...", "B": "...", ...}
                "answer": answer_letter,
                "answer_index": answer_index
            })

    return merged


def process_qa_pair(question_pdf: Path, answer_pdf: Path, output_json: Path, logger: logging.Logger):
    """è™•ç†å–®çµ„é¡Œç›®ç­”æ¡ˆå°ï¼ˆä½¿ç”¨ LLM æ™ºèƒ½è§£æï¼‰"""
    logger.info(f"è™•ç†: {question_pdf.name}")

    # 1. è½‰æ› PDF ç‚º Markdown
    converter = PDFToMarkdownConverter(logger)

    logger.info("è½‰æ›é¡Œç›® PDF...")
    q_markdown = converter.process_pdf(question_pdf)

    logger.info("è½‰æ›ç­”æ¡ˆ PDF...")
    a_markdown = converter.process_pdf(answer_pdf)

    # 2. ä½¿ç”¨ LLM æ™ºèƒ½è§£æé¡Œç›®ï¼ˆä¸éœ€è¦æ‰‹å‹•æå–æ¸¬é©—é¡Œéƒ¨åˆ†ï¼ŒLLM æœƒè‡ªå‹•è­˜åˆ¥ï¼‰
    logger.info("ä½¿ç”¨ LLM è§£æé¡Œç›®...")
    questions = parse_questions_with_llm_enhanced(q_markdown, logger)

    if not questions:
        logger.error("âŒ é¡Œç›®è§£æå¤±æ•—ï¼Œä¸­æ­¢è™•ç†")
        return

    # 3. è§£æç­”æ¡ˆ
    logger.info("è§£æç­”æ¡ˆ...")
    answers = parse_answers_from_table(a_markdown, logger)

    # 4. åˆä½µ
    logger.info("åˆä½µé¡Œç›®èˆ‡ç­”æ¡ˆ...")
    qa_merged = merge_questions_and_answers(questions, answers)

    # 5. å„²å­˜ JSON
    output_data = {
        "metadata": {
            "question_file": question_pdf.name,
            "answer_file": answer_pdf.name,
            "total_questions": len(qa_merged),
            "parsing_method": "LLM (GPT-4o-mini)"  # è¨˜éŒ„ä½¿ç”¨çš„è§£ææ–¹æ³•
        },
        "questions": qa_merged
    }

    with open(output_json, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    logger.info(f"âœ… å„²å­˜å®Œæˆ: {output_json}")
    logger.info(f"   å…±è™•ç† {len(qa_merged)} é¡Œï¼ˆä½¿ç”¨ LLM æ™ºèƒ½è§£æï¼‰")


def main():
    """ä¸»ç¨‹å¼"""
    logger = setup_logger()

    # è³‡æ–™å¤¾è·¯å¾‘
    questions_dir = Path('data/questions')
    answer_dir = Path('data/answer')
    output_dir = Path('output/qa_mapped')
    output_dir.mkdir(parents=True, exist_ok=True)

    # å–å¾—æ‰€æœ‰é¡Œç›®æª”æ¡ˆ
    question_files = sorted(questions_dir.glob('*.pdf'))

    if not question_files:
        logger.error(f"æœªæ‰¾åˆ°é¡Œç›®æª”æ¡ˆæ–¼: {questions_dir}")
        return

    logger.info(f"æ‰¾åˆ° {len(question_files)} å€‹é¡Œç›®æª”æ¡ˆ")

    # è™•ç†æ¯çµ„é¡Œç›®ç­”æ¡ˆ
    for q_file in question_files:
        try:
            # æ‰¾åˆ°å°æ‡‰ç­”æ¡ˆæª”
            a_file = find_matching_answer_file(q_file, answer_dir)

            # ç”¢ç”Ÿè¼¸å‡ºæª”å
            output_json = output_dir / f"{q_file.stem}_mapped.json"

            # è™•ç†
            process_qa_pair(q_file, a_file, output_json, logger)

        except Exception as e:
            logger.error(f"è™•ç†å¤±æ•— {q_file.name}: {e}")
            continue

    logger.info("=" * 60)
    logger.info("âœ… æ‰€æœ‰æª”æ¡ˆè™•ç†å®Œæˆ")


if __name__ == "__main__":
    main()
