#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ³•æ¢æº–å‚™è…³æœ¬ï¼šå°‡æ³•æ¢ PDF è½‰æ›ç‚º CSV

æµç¨‹ï¼š
1. æƒæ data/laws/ ç›®éŒ„ä¸­çš„æ‰€æœ‰ PDF
2. ä½¿ç”¨ MinerU è½‰æ›ç‚º Markdown
3. ä½¿ç”¨ law_articles_converter è½‰æ›ç‚º CSV
4. åˆä½µæ‰€æœ‰æ³•æ¢åˆ°å–®ä¸€ CSV æª”æ¡ˆ
"""

import argparse
import logging
import sys
import tempfile
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.pdf_converter.core import PDFToMarkdownConverter
import pandas as pd

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def convert_law_pdfs_to_csv(laws_dir: Path, output_csv: Path):
    """
    å°‡æ³•æ¢ç›®éŒ„ä¸­çš„æ‰€æœ‰ PDF è½‰æ›ç‚ºå–®ä¸€ CSV

    Args:
        laws_dir: æ³•æ¢ PDF æ‰€åœ¨ç›®éŒ„
        output_csv: è¼¸å‡ºçš„ CSV æª”æ¡ˆè·¯å¾‘
    """
    logger.info(f"ğŸš€ é–‹å§‹è™•ç†æ³•æ¢ PDF: {laws_dir}")

    # æ‰¾å‡ºæ‰€æœ‰ PDF
    pdf_files = list(laws_dir.glob("*.pdf"))
    logger.info(f"æ‰¾åˆ° {len(pdf_files)} å€‹æ³•æ¢ PDF æª”æ¡ˆ")

    if not pdf_files:
        logger.error("æœªæ‰¾åˆ°ä»»ä½• PDF æª”æ¡ˆ")
        return False

    # åˆå§‹åŒ– PDF è½‰æ›å™¨
    converter = PDFToMarkdownConverter()

    # æº–å‚™ CSV è³‡æ–™
    all_articles = []

    # è™•ç†æ¯å€‹ PDF
    for idx, pdf_file in enumerate(pdf_files, 1):
        logger.info(f"è™•ç† [{idx}/{len(pdf_files)}]: {pdf_file.name}")

        try:
            # ä½¿ç”¨è‡¨æ™‚ç›®éŒ„
            with tempfile.TemporaryDirectory() as temp_dir:
                temp_output = Path(temp_dir)

                # è½‰æ›ç‚º Markdown
                markdown_filename = temp_output / f"{pdf_file.stem}.md"
                content = converter.process_pdf(pdf_file, markdown_filename)
                # content å·²ç¶“æ˜¯å­—ç¬¦ä¸²ï¼Œä¸éœ€è¦å†è®€å–

                # è§£ææ³•æ¢
                articles = parse_law_markdown(pdf_file.stem, content)
                all_articles.extend(articles)

                logger.info(f"  âœ… è§£æå‡º {len(articles)} æ¢æ³•æ¢")

        except Exception as e:
            logger.error(f"  âŒ è™•ç†å¤±æ•—: {e}")
            continue

    # è½‰æ›ç‚º DataFrame ä¸¦å„²å­˜
    if all_articles:
        df = pd.DataFrame(all_articles)
        df.to_csv(output_csv, index=False, encoding='utf-8')
        logger.info(f"âœ… æˆåŠŸç”Ÿæˆ CSV: {output_csv}")
        logger.info(f"   ç¸½è¨ˆ {len(all_articles)} æ¢æ³•æ¢")
        return True
    else:
        logger.error("âŒ æœªèƒ½è§£æä»»ä½•æ³•æ¢")
        return False


def parse_law_markdown(law_name: str, content: str) -> list:
    """
    ç°¡å–®çš„æ³•æ¢ Markdown è§£æå™¨

    Args:
        law_name: æ³•è¦åç¨±ï¼ˆå¾æª”åæå–ï¼‰
        content: Markdown å…§å®¹

    Returns:
        æ³•æ¢åˆ—è¡¨
    """
    import re

    articles = []

    # ç°¡å–®çš„æ¨¡å¼ï¼šå°‹æ‰¾ "ç¬¬Xæ¢" çš„æ ¼å¼
    pattern = r'ç¬¬\s*(\d+)\s*æ¢\s*(.+?)(?=ç¬¬\s*\d+\s*æ¢|$)'

    matches = re.finditer(pattern, content, re.DOTALL)

    for match in matches:
        article_no = int(match.group(1))
        article_content = match.group(2).strip()

        # æ¸…ç†å…§å®¹
        article_content = re.sub(r'\n+', ' ', article_content)
        article_content = article_content.strip()

        if article_content:  # åªä¿ç•™éç©ºå…§å®¹
            articles.append({
                'æ³•è¦ä»£ç¢¼': generate_law_code(law_name),
                'æ³•è¦åç¨±': law_name,
                'ä¿®æ­£æ—¥æœŸï¼ˆæ°‘åœ‹ï¼‰': '',
                'æ³•è¦é¡åˆ¥': 'ä¸å‹•ç”¢æ³•è¦',
                'ä¸»ç®¡æ©Ÿé—œ': 'å…§æ”¿éƒ¨',
                'ç« ç¯€ç·¨è™Ÿ': 0,
                'ç« ç¯€æ¨™é¡Œ': '',
                'æ¢æ–‡ä¸»è™Ÿ': article_no,
                'æ¢æ–‡æ¬¡è™Ÿ': 0,
                'æ¢æ–‡å®Œæ•´å…§å®¹': article_content
            })

    return articles


def generate_law_code(law_name: str) -> str:
    """ç”Ÿæˆæ³•è¦ä»£ç¢¼"""
    # ç°¡å–®çš„æ˜ å°„
    code_map = {
        'ä¸å‹•ç”¢ç¶“ç´€æ¥­ç®¡ç†æ¢ä¾‹': 'REAA',
        'ä¸å‹•ç”¢ç¶“ç´€æ¥­ç®¡ç†æ¢ä¾‹æ–½è¡Œç´°å‰‡': 'REAAR',
        'å…¬å¯“å¤§å»ˆç®¡ç†æ¢ä¾‹': 'CMBA',
        'å…¬å¹³äº¤æ˜“æ³•': 'FTLA',
        'æ¶ˆè²»è€…ä¿è­·æ³•': 'CPLA'
    }

    return code_map.get(law_name, 'UNKN')


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(
        description="å°‡æ³•æ¢ PDF è½‰æ›ç‚º CSV",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument(
        '--laws_dir',
        type=Path,
        default=Path('data/laws'),
        help='æ³•æ¢ PDF æ‰€åœ¨ç›®éŒ„ï¼ˆé è¨­: data/lawsï¼‰'
    )

    parser.add_argument(
        '--output',
        type=Path,
        default=Path('data/law_articles.csv'),
        help='è¼¸å‡º CSV æª”æ¡ˆè·¯å¾‘ï¼ˆé è¨­: data/law_articles.csvï¼‰'
    )

    args = parser.parse_args()

    # æª¢æŸ¥è¼¸å…¥ç›®éŒ„
    if not args.laws_dir.exists():
        logger.error(f"æ³•æ¢ç›®éŒ„ä¸å­˜åœ¨: {args.laws_dir}")
        return 1

    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    args.output.parent.mkdir(parents=True, exist_ok=True)

    # åŸ·è¡Œè½‰æ›
    success = convert_law_pdfs_to_csv(args.laws_dir, args.output)

    return 0 if success else 1


if __name__ == "__main__":
    sys.exit(main())
